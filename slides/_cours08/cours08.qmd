---
title: Introduction à la modélisation statistique bayésienne
subtitle: Un cours en R et Stan avec brms
author: Ladislas Nalborczyk (CNRS, LPL, Aix-Marseille Univ)
from: markdown+emoji
format:
  revealjs:
    incremental: true
    theme: [default, ../custom.scss]
    transition: none # fade
    background-transition: none # fade
    transition-speed: default # default, fast, or slow
    slide-number: c/t
    show-slide-number: all
    preview-links: true
    self-contained: true # when sharing slides
    # chalkboard: true
    csl: ../../files/bib/apa7.csl
    logo: ../../files/cover.png
    footer: "Ladislas Nalborczyk - IMSB2026"
    # width: 1200 # defaults to 1050
    # height: 900 # default to 700
    margin: 0.15 # defaults to 0.1
    scrollable: true
    hide-inactive-cursor: true
    pdf-separate-fragments: false
    highlight-style: zenburn
    code-copy: true
    code-link: false
    code-fold: false
    code-summary: "Voir le code"
    numbers: true
    progress: false
title-slide-attributes:
    data-background-color: "#1c5253"
bibliography: ../../files/bib/references.bib
editor_options: 
  chunk_output_type: console
---

## Planning

```{r setup, eval = TRUE, include = FALSE, cache = FALSE}
library(tidyverse)
library(patchwork)
library(brms)
library(imsb)

# setting up knitr options
knitr::opts_chunk$set(
  cache = TRUE, echo = TRUE,
  warning = FALSE, message = FALSE,
  fig.align = "center", dev = "svg"
  )

# setting up ggplot theme
theme_set(theme_bw(base_size = 16, base_family = "Open Sans") )
```

Cours n°01 : Introduction à l'inférence bayésienne <br> Cours n°02 : Modèle Beta-Binomial <br> Cours n°03 : Introduction à brms, modèle de régression linéaire <br> Cours n°04 : Modèle de régression linéaire (suite) <br> Cours n°05 : Markov Chain Monte Carlo <br> Cours n°06 : Modèle linéaire généralisé <br> Cours n°07 : Comparaison de modèles <br> **Cours n°08 : Modèles multi-niveaux (généralisés)** <br> Cours n°09 : Examen final <br>

$$\newcommand\given[1][]{\:#1\vert\:}$$

## Modèles multi-niveaux

Le but est de construire un modèle qui puisse **apprendre à plusieurs
niveaux**, qui puisse produire des estimations qui seront informées par
les différents groupes présents dans les données. Nous allons suivre
l'exemple suivant tout au long de ce cours.

. . .

Imaginons que nous ayons construit un robot visiteur de cafés, et que
celui-ci s'amuse à mesurer le temps d'attente après avoir commandé. Ce
robot visite 20 cafés différents, 5 fois le matin et 5 fois
l'après-midi, et mesure le temps (en minutes) de service d'un café.

```{r echo = FALSE, out.width = "300px"}
knitr::include_graphics("figures/robot.png")
```

## Robot et café

```{r eval = TRUE, echo = TRUE}
library(tidyverse)
library(imsb)

df <- open_data(robot)
head(x = df, n = 15)
```

## Robot et café

```{r eval = TRUE, echo = TRUE, fig.width = 15, fig.height = 5}
df %>%
  ggplot(aes(x = factor(cafe), y = wait, fill = factor(afternoon) ) ) +
  geom_dotplot(
    stackdir = "center", binaxis = "y",
    dotsize = 1, show.legend = FALSE
    ) +
  geom_hline(yintercept = mean(df$wait), linetype = 3) +
  facet_wrap(~afternoon, ncol = 2) +
  labs(x = "Café", y = "Temps d'attente (en minutes)")
```

## Robot et café, premier modèle

On peut construire un premier modèle, qui estime le temps moyen (sur
tous les bistrots confondus) pour être servi.

$$
\begin{align}
\color{orangered}{w_{i}} \ &\color{orangered}{\sim \mathrm{Normal}(\mu_{i}, \sigma)} \\
\color{black}{\mu_{i}} \ &\color{black}{= \alpha} \\
\color{steelblue}{\alpha} \ &\color{steelblue}{\sim \mathrm{Normal}(5, 10)} \\
\color{steelblue}{\sigma} \ &\color{steelblue}{\sim \mathrm{HalfCauchy}(0, 2)} \\
\end{align}
$$

## Half-Cauchy

$$
p(x \given x_{0}, \gamma) = \left(\pi \gamma \left[1 + \left(\frac{x-x_{0}}{\gamma}\right)^{2}\right] \right)^{-1}
$$

```{r eval = TRUE, echo = TRUE, ig.width = 7.5, fig.height = 5}
ggplot(data = data.frame(x = c(0, 10) ), aes(x = x) ) +
    stat_function(
        fun = dcauchy,
        args = list(location = 0, scale = 2), size = 1.5
        )
```

## Robot et café, premier modèle

```{r eval = TRUE, echo = TRUE, results = "hide"}
library(brms)

mod1 <- brm(
  formula = wait ~ 1,
  prior = c(
    prior(normal(5, 10), class = Intercept),
    prior(cauchy(0, 2), class = sigma)
    ),
  data = df,
  # on utilise tous les coeurs disponibles
  cores = parallel::detectCores()
  )
```

. . .

```{r eval = TRUE, echo = TRUE, warning = FALSE}
posterior_summary(x = mod1, probs = c(0.025, 0.975), pars = c("^b_", "sigma") )
```

## Diagnostic plot

```{r eval = TRUE, echo = TRUE, fig.width = 14, fig.height = 7}
plot(
  x = mod1, combo = c("dens_overlay", "trace"),
  theme = theme_bw(base_size = 16, base_family = "Open Sans")
  )
```

## Un intercept par café

Deuxième modèle qui estime un intercept par café. Équivalent à
construire 20 dummy variables.

$$
\begin{align}
\color{orangered}{w_{i}} \ &\color{orangered}{\sim \mathrm{Normal}(\mu_{i}, \sigma)} \\
\color{black}{\mu_{i}} \ &\color{black}{= \alpha_{\text{café}[i]}} \\
\color{steelblue}{\alpha_{\text{café}[i]}} \ &\color{steelblue}{\sim \mathrm{Normal}(5, 10)} \\
\color{steelblue}{\sigma} \ &\color{steelblue}{\sim \mathrm{HalfCauchy}(0, 2)} \\
\end{align}
$$

```{r eval = TRUE, echo = TRUE, results = "hide"}
mod2 <- brm(
  formula = wait ~ 0 + factor(cafe),
  prior = c(
    prior(normal(5, 10), class = b),
    prior(cauchy(0, 2), class = sigma)
    ),
  data = df,
  cores = parallel::detectCores()
  )
```

## Un intercept par café

```{r eval = TRUE, echo = TRUE, warning = FALSE}
posterior_summary(x = mod2, pars = "^b_")
```

## Modèle multi-niveaux

Est-ce qu'on ne pourrait pas faire en sorte que le temps mesuré au café
1 **informe** la mesure réalisée au café 2, et au café 3 ? Ainsi que le
temps moyen pour être servi ? Nous allons apprendre le prior à partir
des données...

$$
\begin{align}
\text{Niveau 1}: \color{orangered}{w_{i}} \ &\color{orangered}{\sim \mathrm{Normal}(\mu_{i}, \sigma)} \\
\color{black}{\mu_{i}} \ &\color{black}{= \alpha_{\text{café}[i]}} \\
\text{Niveau 2}: \color{steelblue}{\alpha_{\text{café}}} \ &\color{steelblue}{\sim \mathrm{Normal}(\alpha,\sigma_{\text{café}})} \\
\color{steelblue}{\alpha} \ &\color{steelblue}{\sim \mathrm{Normal}(5, 10)} \\
\color{steelblue}{\sigma_{\text{café}}} \ &\color{steelblue}{\sim \mathrm{HalfCauchy}(0, 2)} \\
\color{steelblue}{\sigma} \ &\color{steelblue}{\sim \mathrm{HalfCauchy}(0, 2)} \\
\end{align}
$$

Le prior de l'intercept pour chaque café ($\alpha_{\text{café}}$) est
maintenant fonction de deux paramètres ($\alpha$ et
$\sigma_{\text{café}}$). $\alpha$ et $\sigma_{\text{café}}$ sont appelés
des **hyper-paramètres**, ce sont des paramètres pour des paramètres, et
leurs priors sont appelés des **hyperpriors**. Il y a deux niveaux dans
le modèle...

## Équivalences (encore)

$$
\begin{align}
\color{orangered}{w_{i}} \ &\color{orangered}{\sim \mathrm{Normal}(\mu_{i}, \sigma)} \\
\color{black}{\mu_{i}} \ &\color{black}{= \alpha_{\text{café}[i]}} \\
\color{steelblue}{\alpha_{\text{café}}} \ &\color{steelblue}{\sim \mathrm{Normal}(\alpha,\sigma_{\text{café}})} \\
\end{align}
$$

NB : $\alpha$ est ici défini dans le prior de $\alpha_{\text{café}}$
mais on pourrait, de la même manière, le définir dans le modèle linéaire
:

$$
\begin{align}
\color{orangered}{w_{i}} \ &\color{orangered}{\sim \mathrm{Normal}(\mu_{i}, \sigma)} \\
\color{black}{\mu_{i}} \ &\color{black}{= \alpha + \alpha_{\text{café}[i]}} \\
\color{steelblue}{\alpha_{\text{café}}} \ &\color{steelblue}{\sim \mathrm{Normal}(0,\sigma_{\text{café}})} \\
\end{align}
$$

On peut toujours "enlever" la moyenne d'une distribution gaussienne et
la considérer comme une constante plus une gaussienne centrée sur zéro.

. . .

NB : quand $\alpha$ est défini dans le modèle linéaire, les
$\alpha_{\text{café}}$ représentent des déviations de l'intercept moyen.
Il faut donc ajouter $\alpha$ et $\alpha_{\text{café}}$ pour obtenir le
temps d'attente moyen par café...

## Équivalences (encore)

```{r eval = TRUE, echo = TRUE, out.width = "33%"}
y1 <- rnorm(n = 1e4, mean = 5, sd = 1)
y2 <- rnorm(n = 1e4, mean = 0, sd = 1) + 5

data.frame(y1 = y1, y2 = y2) %>%
    pivot_longer(cols = 1:2, names_to = "x", values_to = "y") %>%
    ggplot(aes(x = y, colour = x) ) +
    geom_density(show.legend = FALSE)
```

## {background-iframe="http://mfviz.com/hierarchical-models/"}

## Modèle multi-niveaux

```{r eval = TRUE, echo = TRUE, results = "hide"}
mod3 <- brm(
  formula = wait ~ 1 + (1 | cafe),
  prior = c(
    prior(normal(5, 10), class = Intercept),
    prior(cauchy(0, 2), class = sigma),
    prior(cauchy(0, 2), class = sd)
    ),
  data = df,
  warmup = 1000, iter = 5000,
  cores = parallel::detectCores()
  )
```

Ce modèle a 23 paramètres, l'intercept général $\alpha$, la variabilité
résiduelle $\sigma$, la variabilité entre les cafés
$\sigma_{\text{café}}$, et un intercept par café.

## Shrinkage

```{r echo = FALSE, fig.width = 14, fig.height = 8}
library(wesanderson) # for plotting
post <- as_draws_df(mod3) # extracts posterior samples

df %>%
    group_by(cafe) %>%
    summarise(Observed = mean(wait) ) %>%
    mutate(Estimated = coef(mod3)$cafe[, , ] %>% data.frame %>% pull(Estimate) ) %>%
    gather(type, Observed, Observed:Estimated) %>%
    ggplot(aes(x = cafe, y = Observed, fill = type) ) +
    geom_hline(yintercept = mean(post$b_Intercept), linetype = 2) +
    geom_point(pch = 21, size = 5, alpha = 0.8, colour = "white", show.legend = TRUE) +
    scale_color_manual(values = rev(wes_palette(n = 2, name = "Chevalier1") ) )  +
    scale_fill_manual(values = rev(wes_palette(n = 2, name = "Chevalier1") ) )  +
    scale_x_continuous(name = "Café", breaks = 1:20) +
    ylab("Temps d'attente (en minutes)") +
    theme(legend.title = element_blank() )
```

## Shrinkage magic [@efron1977]

```{r echo = FALSE, fig.align = "center", out.width = "66%"}
knitr::include_graphics("figures/stein1.png")
```

L'estimateur James-Stein est défini comme $z = \bar{y} + c(y - \bar{y})$,
où $\bar{y}$ désigne la moyenne de l'échantillon, $y$ une observation individuelle,
et $c$ une constante, le **shrinking factor** [@efron1977].

## Shrinkage magic [@efron1977]

Le shrinking factor est déterminé à la fois par la variabilité (imprécision) de la mesure (e.g., son écart-type) et par la distance à l'estimation moyenne (i.e., $y - \bar{y}$). En d'autres termes, cet estimateur fait moins "confiance" (i.e., accorde moins de poids) aux observations imprécises et/ou extrêmes. En pratique, le shrinkage agit comme une protection contre le sur-apprentissage (overfitting).

```{r echo = FALSE, fig.align = "center", out.width = "75%"}
knitr::include_graphics("figures/stein2.png")
```

## Pooling

Le **shrinkage** observé slide précédente est dû à des phénomènes de
partage (pooling) de l'information entre les cafés. L'estimation de
l'intercept pour chaque café informe l'estimation de l'intercept des
autres cafés, ainsi que l'estimation de l'intercept général (i.e., la
moyenne générale).

. . .

On distingue en général trois perspectives (ou stratégies) :

-   **Complete pooling** : on suppose que le temps d'attente est
    invariant, on estime un intercept commun (`mod1`).

-   **No pooling** : on suppose que les temps d'attente de chaque café
    sont uniques et indépendants : on estime un intercept par café, mais
    sans informer le niveau supérieur (`mod2`).

-   **Partial pooling** : on utilise un prior adaptatif, comme dans
    l'exemple précédent (`mod3`).

. . .

La stratégie **complete pooling** en général underfitte les données
(faibles capacités de prédiction) tandis que le stratégie **no pooling**
revient à overfitter les données (faibles capacités de prédiction ici
aussi). La stratégie **partial pooling** (i.e., celle des modèles multi-niveaux)
permet d''équilibrer underfitting et overfitting.

## Comparaison de modèles

On peut comparer ces trois modèles en utilisant le WAIC (discuté au
Cours n°07).

```{r eval = TRUE, echo = TRUE}
# calcul du WAIC et ajout du WAIC à chaque modèle
mod1 <- add_criterion(mod1, "waic")
mod2 <- add_criterion(mod2, "waic")
mod3 <- add_criterion(mod3, "waic")

# comparaison des WAIC de chaque modèle
w <- loo_compare(mod1, mod2, mod3, criterion = "waic")
print(w, simplify = FALSE)
```

On remarque que le modèle 3 a seulement 18 "effective parameters"
(pWAIC) et moins de paramètres que le modèle 2, alors qu'il en a en
réalité 2 de plus... `posterior_summary(mod3)[3, 1]` nous donne le
sigma du prior adaptatif des $\alpha_{\text{café}}$
($\sigma_{\text{café}} = 0.82$). On remarque que ce sigma est très
faible et correspond à assigner un prior très contraignant, ou
**régularisateur**.

## Comparaison de modèles

On compare les estimations du premier modèle (complete pooling model) et du troisième
modèle (partial pooling model).

```{r eval = TRUE, echo = TRUE}
posterior_summary(mod1, pars = c("^b", "sigma") )
posterior_summary(mod3, pars = c("^b", "sigma") )
```

Les deux modèles font la même prédiction (en moyenne) pour $\alpha$,
mais le modèle 3 est plus incertain de sa prédiction que le modèle 1 (voir l'erreur standard pour $\alpha$)...

. . .

L'estimation de $\sigma$ du modèle 3 est plus petite que celle du modèle
1 car le modèle 3 **décompose** la variabilité non expliquée en deux
sources : la variabilité du temps d'attente entre les cafés
$\sigma_{\text{café}}$ et la variabilité résiduelle $\sigma$.

## Robot et café

Imaginons que notre robot ne visite pas tous les cafés le même nombre de
fois (comme dans le cas précédent) mais qu'il visite plus souvent les
cafés proches de chez lui...

```{r eval = TRUE, echo = TRUE, results = "hide"}
df2 <- open_data(robot_unequal) # nouveau jeu de données

mod4 <- brm(
  formula = wait ~ 1 + (1 | cafe),
  prior = c(
    prior(normal(5, 10), class = Intercept),
    prior(cauchy(0, 2), class = sigma),
    prior(cauchy(0, 2), class = sd)
    ),
  data = df2,
  warmup = 1000, iter = 5000,
  cores = parallel::detectCores()
  )
```

## Shrinkage

On observe que les cafés qui sont souvent visités (à droite) subissent
moins l'effet du **shrinkage**. Leur estimation est moins "tirée" vers la
moyenne générale que les estimations des cafés les moins souvent visités
(à gauche).

```{r echo = FALSE, fig.width = 12, fig.height = 6}
post <- as_draws_df(mod4)

df2 %>%
    group_by(cafe) %>%
    summarise(Observed = mean(wait) ) %>%
    mutate(Estimated = coef(mod4)$cafe[, , ] %>% data.frame %>% pull(Estimate) ) %>%
    gather(type, Observed, Observed:Estimated) %>%
    ggplot(aes(x = cafe, y = Observed, fill = type) ) +
    geom_hline(yintercept = mean(post$b_Intercept), linetype = 2) +
    geom_point(pch = 21, size = 5, alpha = 0.8, colour = "white", show.legend = TRUE) +
    scale_color_manual(values = rev(wes_palette(n = 2, name = "Chevalier1") ) )  +
    scale_fill_manual(values = rev(wes_palette(n = 2, name = "Chevalier1") ) )  +
    scale_x_continuous(name = "Café (du moins visité au plus visité)", breaks = 1:20) +
    ylab("Temps d'attente (en minutes)") +
    theme(legend.title = element_blank() )
```

## Aparté : effets fixes et effets aléatoires

Cinq définitions (contradictoires) relevées par @gelman2005.

-   Fixed effects are constant across individuals, and random effects
    vary.
-   Effects are fixed if they are interesting in themselves or random if
    there is interest in the underlying population.
-   When a sample exhausts the population, the corresponding variable is
    fixed; when the sample is a small (i.e., negligible) part of the
    population the corresponding variable is random.
-   If an effect is assumed to be a realized value of a random variable,
    it is called a random effect.
-   Fixed effects are estimated using least squares (or, more generally,
    maximum likelihood) and random effects are estimated with shrinkage.

. . .

@gelman2006a suggèrent plutôt l'utilisation des termes de **constant
effects** et **varying effects**, et de toujours utiliser la modélisation
multi-niveaux, en considérant que ce qu'on appelle **effet fixe** peut
simplement être considéré comme un **effet aléatoire** dont la variance
serait égale à $0$.

## Régularisation et terminologie

Le fait de faire varier les intercepts de chaque café est simplement une
autre manière de régulariser (de manière adaptative), c'est à dire de
diminuer le poids accordé aux données dans l'estimation. Le modèle
devient à même d'estimer à quel point les groupes (ici les cafés) sont
différents, tout en estimant les caractéristiques de chaque café...

. . .

Différence entre les **cross-classified** (ou "crossed") multilevel
models et **nested or hierarchical** multilevel models. Le premier type
de modèle concerne des données structurées selon deux (ou plus) facteurs
aléatoires non "nichés". Le deuxième type de modèles concerne des
données structurées de manière hiérarchique (e.g., un élève dans une
classe dans une école dans une ville...). Voir [cette
discussion](https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified)
pour plus de détails.

. . .

Les deux types de modèles s'écrivent cependant de manière similaire, sur
plusieurs "niveaux". Le terme "multi-niveaux" (dans notre terminologie)
fait donc référence à la structure du modèle, à sa spécification. À
distinguer de la structure des données.

## Exemple de modèle "cross-classified"

On pourrait se poser la question de savoir si la récence des cafés (leur
âge) ne serait pas une source de variabilité non contrôlée ? Il suffit
d'ajouter un intercept qui varie par âge, et de lui attribuer un prior
adaptatif.

$$
\begin{align}
\color{orangered}{w_{i}} \ &\color{orangered}{\sim \mathrm{Normal}(\mu_{i}, \sigma)} \\
\color{black}{\mu_{i}} \ &\color{black}{= \alpha + \alpha_{\text{café}[i]} + \alpha_{\text{âge}[i]}} \\
\color{steelblue}{\alpha_{\text{café}}} \ &\color{steelblue}{\sim \mathrm{Normal}(5, \sigma_{\text{café}})} \\
\color{steelblue}{\alpha_{\text{âge}}} \ &\color{steelblue}{\sim \mathrm{Normal}(5, \sigma_{\text{âge}})} \\
\color{steelblue}{\alpha} \ &\color{steelblue}{\sim \mathrm{Normal}(0, 10)} \\
\color{steelblue}{\sigma_{\text{café}}} \ &\color{steelblue}{\sim \mathrm{HalfCauchy}(0, 2)} \\
\color{steelblue}{\sigma_{\text{âge}}} \ &\color{steelblue}{\sim \mathrm{HalfCauchy}(0, 2)} \\
\color{steelblue}{\sigma} \ &\color{steelblue}{\sim \mathrm{HalfCauchy}(0, 2)} \\
\end{align}
$$

## Robot et café : varying intercept + varying slope

On s'intéresse maintenant à l'effet du moment de la journée sur le temps
d'attente. Attend-on plus le matin, ou l'après-midi ?

$$
\begin{align}
\color{orangered}{w_{i}} \ &\color{orangered}{\sim \mathrm{Normal}(\mu_{i}, \sigma)} \\
\color{black}{\mu_{i}} \ &\color{black}{= \alpha_{\text{café}[i]} + \beta_{\text{café}[i]} \times A_{i}} \\
\end{align}
$$

Où $A_{i}$ est une dummy variable codée 0/1 pour le matin et
l'après-midi et où $\beta_{\text{café}}$ est donc un paramètre de différence
(i.e., une pente) entre le matin et l'après-midi.

. . .

Remarque : on sait que les cafés ont des intercepts et des pentes qui
co-varient... Les cafés populaires seront surchargés le matin et beaucoup
moins l'après-midi, résultant en une pente importante. Ces cafés auront
aussi un temps d'attente moyen plus long (i.e., un intercept plus
grand). Dans ces cafés, $\alpha$ est grand et $\beta$ est loin de zéro.
À l'inverse, dans un café peu populaire, le temps d'attente sera faible,
ainsi que la différence entre matin et après-midi.

. . .

On pourrait donc utiliser la co-variation entre intercept et pente pour
faire de meilleures inférences. Autrement dit, faire en sorte que
l'estimation de l'intercept informe celle de la pente, et
réciproquement.

## Robot et café : varying intercept + varying slope

On s'intéresse maintenant à l'effet du moment de la journée sur le temps
d'attente. Attend-on plus le matin, ou l'après-midi ?

$$
\begin{align}
\color{orangered}{w_{i}} \ &\color{orangered}{\sim \mathrm{Normal}(\mu_{i}, \sigma)} \\
\color{black}{\mu_{i}} \ &\color{black}{= \alpha_{\text{café}[i]} + \beta_{\text{café}[i]} \times A_{i}} \\
\color{steelblue}{\begin{bmatrix}
\alpha_{\text{café}} \\
\beta_{\text{café}} \\
\end{bmatrix}} \ &\color{steelblue}{\sim \mathrm{MVNormal}\bigg(\begin{bmatrix} \alpha \\ \beta \end{bmatrix}, \textbf{S}\bigg)} \\
\end{align}
$$

La troisième ligne postule que chaque café a un intercept
$\alpha_{\text{café}}$ et une pente $\beta_{\text{café}}$, définis par
un prior Gaussien bivarié (i.e., à deux dimensions) ayant comme moyennes
$\alpha$ et $\beta$ et comme matrice de covariance $\textbf{S}$.

## Aparté : distribution gaussienne multivariée

$$\mathbf{x} \sim \mathcal{N}(\boldsymbol{\mu}, \boldsymbol{\Sigma})$$

Où $\boldsymbol{\mu}$ est un vecteur (à $k$ dimensions) de moyennes, par
exemple: `mu <- c(a, b)`.

. . .

$\boldsymbol{\Sigma}$ est une matrice de covariance de $k \times k$
dimensions, et qui correspond à la matrice donnée par la fonction
`vcov()`.

$$
\begin{align}
\boldsymbol{\Sigma} &=
\begin{pmatrix}
\sigma_{\alpha}^{2} & \sigma_{\alpha} \sigma_{\beta} \rho \\
\sigma_{\alpha} \sigma_{\beta} \rho & \sigma_{\beta}^{2} \\
\end{pmatrix} \\
\end{align}
$$

## Aparté : distribution gaussienne multivariée

<!--

<center>
<iframe width=1200 height = 800 scrolling="no" frameborder="0" src="https://www.wolframcloud.com/obj/demonstrations/Published/TheBivariateNormalDistribution?_view=EMBED" style="border:0;"></iframe>
</center>

-->

```{r echo = FALSE, out.width = "800px"}
knitr::include_graphics("figures/bivariate.png")
```

## Aparté : distribution gaussienne multivariée

$$
\begin{align}
\boldsymbol{\Sigma} &=
\begin{pmatrix}
\sigma_{\alpha}^{2} & \sigma_{\alpha} \sigma_{\beta} \rho \\
\sigma_{\alpha} \sigma_{\beta} \rho & \sigma_{\beta}^{2} \\
\end{pmatrix} \\
\end{align}
$$

Cette matrice peut se construire de deux manières différentes,
strictement équivalentes.

```{r eval = TRUE, echo = TRUE}
sigma_a <- 1
sigma_b <- 0.75
rho <- 0.7
cov_ab <- sigma_a * sigma_b * rho
(Sigma1 <- matrix(c(sigma_a^2, cov_ab, cov_ab, sigma_b^2), ncol = 2) )
```

## Aparté : distribution gaussienne multivariée

$$
\begin{align}
\boldsymbol{\Sigma} &=
\begin{pmatrix}
\sigma_{\alpha}^{2} & \sigma_{\alpha} \sigma_{\beta} \rho \\
\sigma_{\alpha} \sigma_{\beta} \rho & \sigma_{\beta}^{2} \\
\end{pmatrix} \\
\end{align}
$$

La deuxième méthode est pratique car elle considère séparément les
écart-types et les corrélations.

```{r eval = TRUE, echo = TRUE}
(sigmas <- c(sigma_a, sigma_b) ) # standard deviations
(Rho <- matrix(c(1, rho, rho, 1), nrow = 2) ) # correlation matrix
(Sigma2 <- diag(sigmas) %*% Rho %*% diag(sigmas) )
```

## Robot et café : varying intercept + varying slope

$$
\begin{align}
\color{orangered}{w_{i}} \ &\color{orangered}{\sim \mathrm{Normal}(\mu_{i}, \sigma)} \\
\color{black}{\mu_{i}} \ &\color{black}{= \alpha_{\text{café}[i]} + \beta_{\text{café}[i]} \times A_{i}} \\
\color{steelblue}{\begin{bmatrix}
\alpha_{\text{café}} \\
\beta_{\text{café}} \\
\end{bmatrix}} \ &\color{steelblue}{\sim \mathrm{MVNormal}\bigg(\begin{bmatrix} \alpha \\ \beta \end{bmatrix}, \textbf{S}\bigg)} \\
\color{black}{\textbf{S}} \ &\color{black}{=
\begin{pmatrix}
\sigma_{\alpha} & 0 \\
0 & \sigma_{\beta} \\
\end{pmatrix} \
\textbf{R} \begin{pmatrix}
\sigma_{\alpha} & 0 \\
0 & \sigma_{\beta} \\
\end{pmatrix}} \\
\color{steelblue}{\alpha} \ &\color{steelblue}{\sim \mathrm{Normal} (0, 10)} \\
\color{steelblue}{\beta} \ &\color{steelblue}{\sim \mathrm{Normal} (0, 10)} \\
\color{steelblue}{\sigma_{\alpha}} \ &\color{steelblue}{\sim \mathrm{HalfCauchy} (0, 2)} \\
\color{steelblue}{\sigma_{\beta}} \ &\color{steelblue}{\sim \mathrm{HalfCauchy} (0, 2)} \\
\color{steelblue}{\sigma} \ &\color{steelblue}{\sim \mathrm{HalfCauchy} (0, 2)} \\
\color{steelblue}{\textbf{R}} \ &\color{steelblue}{\sim \mathrm{LKJ}(2)} \\
\end{align}
$$

$\textbf{S}$ est définie en factorisant $\sigma_{\alpha}$,
$\sigma_{\beta}$, et la matrice de corrélation $\textbf{R}$. La suite du
modèle définit simplement les priors pour les effets constants. La
dernière ligne spécifie le prior pour $\textbf{R}$.

## LKJ prior

Prior proposé par @lewandowski2009. Un seul paramètre $\zeta$ (zeta) spécifie la
concentration de la distribution du coefficient de corrélation. Le prior
$\mathrm{LKJ}(2)$ définit un prior peu informatif pour $\rho$ (rho) qui est
sceptique des corrélations extrêmes (i.e., des valeurs proches de $-1$ ou $1$).

```{r, echo = FALSE, fig.width = 14, fig.height = 7, cache = TRUE}
library(ggdist)

expand.grid(eta = c(0.5, 2, 5, 10), K = c(2, 3, 4, 5) ) %>%
  ggplot(
      aes(
          y = ordered(eta), dist = "lkjcorr_marginal",
          arg1 = K, arg2 = eta, fill = as.factor(eta)
          )
      ) +
  stat_dist_slab(p_limits = c(0, 1), alpha = 0.8) +
  facet_grid(~paste0(K, "x", K) ) +
  labs(x = expression(rho), y = "Densité de probabilité (par prior)") +
  scale_fill_manual(
      values = c("steelblue", "orangered", "purple", "darkgreen"),
      labels = c(
        expression(paste(zeta, " = ", "0.5") ),
        expression(paste(zeta, " = ", "2") ),
        expression(paste(zeta, " = ", "10") ),
        expression(paste(zeta, " = ", "50") )
        )
      ) +
    theme(
        legend.title = element_blank(),
        legend.text.align = 0,
        legend.background = element_rect(size = 0.5, colour = "black")
        )
```

## Rappels de syntaxe

Le paquet `brms` utilise la même syntaxe que les fonctions de base R
(comme `lm`) ou que le paquet `lme4`.

```{r eval = FALSE, echo = TRUE}
Reaction ~ Days + (1 + Days | Subject)
```

La partie gauche représente notre variable dépendante (ou "outcome",
i.e., ce qu'on essaye de prédire).

. . .

La partie droite permet de définir les prédicteurs. L'intercept est
généralement implicite, de sorte que les deux écritures ci-dessous sont
équivalentes.

```{r eval = FALSE, echo = TRUE}
Reaction ~ Days + (1 + Days | Subject)
Reaction ~ 1 + Days + (1 + Days | Subject)
```

## Rappels de syntaxe

La première partie de la partie droite de la formule représente les
effets constants (effets fixes), tandis que la seconde partie (entre
parenthèses) représente les effets "variants" ou "variables" (effets aléatoires).

```{r eval = FALSE, echo = TRUE}
Reaction ~ 1 + Days + (1 | Subject)
Reaction ~ 1 + Days + (1 + Days | Subject)
```

Le premier modèle ci-dessus contient seulement un intercept variable,
qui varie par `Subject`. Le deuxième modèle contient également un
intercept variable, mais aussi une pente variable pour l'effet de
`Days`.

## Rappels de syntaxe

Lorsqu'on inclut plusieurs effets variants (e.g., un intercept et une
pente variables), `brms` postule qu'on souhaite aussi estimer la
corrélation entre ces deux effets. Dans le cas contraire, on peut
supprimer cette corrélation (i.e., la fixer à 0) en utilisant `||`.

```{r eval = FALSE, echo = TRUE}
Reaction ~ Days + (1 + Days || Subject)
```

. . .

Les modèles précédents postulaient un modèle génératif Gaussien. Ce
postulat peut être changé facilement en spécifiant la fonction souhaitée
via l'argument `family`.

```{r eval = FALSE, echo = TRUE}
brm(formula = Reaction ~ 1 + Days + (1 + Days | Subject), family = lognormal() )
```

## Modèle brms

On spécifie un intercept et une pente (pour l'effet d'`afternoon`) qui
varient par `cafe`.

```{r eval = TRUE, echo = TRUE, results = "hide"}
mod5 <- brm(
  formula = wait ~ 1 + afternoon + (1 + afternoon | cafe),
  prior = c(
    prior(normal(0, 10), class = Intercept),
    prior(normal(0, 10), class = b),
    prior(cauchy(0, 2), class = sigma),
    prior(cauchy(0, 2), class = sd)
    ),
  data = df,
  warmup = 1000, iter = 5000,
  cores = parallel::detectCores()
  )
```

## Distribution postérieure

```{r eval = TRUE, echo = TRUE, fig.width = 9, fig.height = 6}
post <- as_draws_df(x = mod5) # extracts posterior samples
R <- rethinking::rlkjcorr(n = 16000, K = 2, eta = 2) # samples from prior

data.frame(prior = R[, 1, 2], posterior = post$cor_cafe__Intercept__afternoon) %>%
    gather(type, value, prior:posterior) %>%
    ggplot(aes(x = value, color = type, fill = type) ) +
    geom_histogram(position = "identity", alpha = 0.2) +
    labs(x = expression(rho), y = "Nombre d'échantillons")
```

## Shrinkage en deux dimensions

```{r eval = TRUE, echo = FALSE, fig.width = 12, fig.height = 8}
a1 <- sapply(1:20, function(i) mean(df$wait[df$cafe == i & df$afternoon == 0]) )
b1 <- sapply(1:20, function(i) mean(df$wait[df$cafe == i & df$afternoon == 1]) ) - a1

no_pooling <-
  data.frame(Intercept = a1, afternoon = b1) %>%
  mutate(model = "no pooling")

partial_pooling <-
  data.frame(coef(mod5)$cafe[, 1, 1:2]) %>%
  mutate(model = "partial pooling")

shrinkage <- bind_rows(no_pooling, partial_pooling)

mu <- c(mean(post$b_Intercept), mean(post$b_afternoon) )
rho <- mean(post$cor_cafe__Intercept__afternoon)
sda <- mean(post$sd_cafe__Intercept)
sdb <- mean(post$sd_cafe__afternoon)
cov_ab <- sda * sdb * rho
sigma <- matrix(c(sda^2, cov_ab, cov_ab, sdb^2), ncol = 2)

##############################################################################
# Helper function to make ellipse, credits to Tristan Mahr                   #
# https://tjmahr.github.io/plotting-partial-pooling-in-mixed-effects-models/ #
##############################################################################

library(ellipse)

make_ellipse <- function(cov_mat, center, level) {
    
    ellipse(cov_mat, centre = center, level = level) %>%
        as.data.frame() %>%
        add_column(level = level)
    
}

levels <- c(.1, .3, .5, .7)

df_ellipse <-
    levels %>%
    purrr::map_df(~ make_ellipse(sigma, mu, level = .x) ) %>% 
    rename(Intercept = x, afternoon = y)

shrinkage %>%
    mutate(id = rep(1:20, 2) ) %>%
    ggplot(aes(x = Intercept, y = afternoon, color = model) ) +
    scale_color_manual(values = wesanderson::wes_palette(n = 2, name = "Chevalier1") ) +
    geom_point(size = 5, show.legend = FALSE) +
    # connecting lines
    geom_path(
        aes(group = id, color = NULL),
        arrow = arrow(length = unit(.015, "npc"), type = "closed"), 
        show.legend = FALSE
        ) +
    # ellipses
    geom_path(
        aes(group = level, color = NULL),
        data = df_ellipse,
        linetype = "dashed", color = "grey40", alpha = 0.8
        ) +
    labs(x = "Intercept", y = "Slope")
```

## Comparaison de modèles

On compare le premier modèle (complete pooling model), le troisième
modèle (partial pooling model), et le dernier modèle (avec intercept et pente variable).

```{r eval = TRUE, echo = TRUE}
# comparaison des WAIC de chaque modèle
mod5 <- add_criterion(mod5, "waic")
w <- loo_compare(mod1, mod2, mod3, mod5, criterion = "waic")
print(w, simplify = FALSE)
model_weights(mod1, mod2, mod3, mod5, weights = "waic")
```

## Comparaison de modèles

L'estimation du temps d'attente moyen est plus incertaine lorsqu'on
prend en compte de nouvelles sources d'erreur. Cependant, l'erreur du
modèle (i.e., ce qui n'est pas expliqué), la variation résiduelle
$\sigma$, diminue...

```{r eval = TRUE, echo = TRUE, warning = FALSE}
posterior_summary(mod1, pars = c("^b", "sigma") )
posterior_summary(mod3, pars = c("^b", "sigma") )
posterior_summary(mod5, pars = c("^b", "sigma") )
```

## Conclusions

Les modèles multi-niveaux (ou "modèles mixtes") sont des extensions
naturelles des modèles de régression classiques, où les paramètres de
ces derniers se voient eux-même attribués des "modèles", gouvernés par
des hyper-paramètres.

. . .

Cette extension permet de faire des prédictions plus précises en prenant
en compte la variabilité liée aux groupes ou structures (clusters)
présent(e)s dans les données. Autrement dit, en modélisant les
populations d'où sont tirés les effets aléatoires (e.g., la population
de participants ou de stimuli).

Un modèle de régression classique est équivalent à un modèle
multi-niveaux où la variabilité des effets aléatoires serait fixée à
$0$.

. . .

La cadre bayésien permet une interprétation naturelle des distributions
desquelles proviennent les effets aléatoires (varying effects). En
effet, ces distributions peuvent être interprétées comme des
distributions a priori, dont les paramètres sont estimés à partir des
données.

## Mise en pratique - Modèles multi-niveaux généralisés

Travailler avec des sujets humains implique un minimum de coopération
réciproque. Mais ce n'est pas toujours le cas. Une partie
non-négligeable des étudiants qui s'inscrivent pour passer des
expériences de psychologie ne se présentent pas le jour prévu... On a
voulu estimer la **probabilité de présence d'un étudiant inscrit** en
fonction de l'envoi (ou non) d'un mail de rappel (cet exemple est
présenté en détails dans deux blogposts, accessibles
[ici](http://www.barelysignificant.com/post/absenteeism/), et
[ici](http://www.barelysignificant.com/post/absenteeism2/)).

```{r eval = TRUE, echo = TRUE}
library(tidyverse)
library(imsb)

# import des données
absence_data <- open_data(absence_multilevel)

# on affiche 12 lignes "au hasard" dans ces données
absence_data %>% slice_sample(prop = 1) %>% head()
```

## Mise en pratique - absentéisme expérimental

$$
\begin{aligned}
\color{orangered}{y_{i}} \ &\color{orangered}{\sim \mathrm{Binomial}(n_{i}, p_{i})} \\
\color{black}{\text{logit}(p_{i})} \ &\color{black}{= \alpha_{\text{researcher}_{[i]}} + \beta_{\text{researcher}_{[i]}} \times \text{reminder}_{i}} \\
\color{steelblue}{\begin{bmatrix}
\alpha_{\text{researcher}} \\
\beta_{\text{researcher}} \\
\end{bmatrix}} \ & \color{steelblue}{\sim \mathrm{MVNormal}\left(\begin{bmatrix} \alpha \\ \beta \end{bmatrix}, \textbf{S}\right)} \\
\color{steelblue}{\textbf{S}} \ &\color{steelblue}{=
\begin{pmatrix}
\sigma_{\alpha} & 0 \\
0 & \sigma_{\beta} \\
\end{pmatrix}
\textbf{R} \begin{pmatrix}
\sigma_{\alpha} & 0 \\
0 & \sigma_{\beta} \\
\end{pmatrix}} \\
\color{steelblue}{\alpha} \ &\color{steelblue}{\sim \mathrm{Normal}(0, 1)} \\
\color{steelblue}{\beta} \ &\color{steelblue}{\sim \mathrm{Normal}(0, 1)} \\
\color{steelblue}{(\sigma_{\alpha}, \sigma_{\beta})}\ &\color{steelblue}{\sim \mathrm{HalfCauchy}(0, 1)} \\
\color{steelblue}{\textbf{R}} \ &\color{steelblue}{\sim \mathrm{LKJcorr}(2)} \\
\end{aligned}
$$

Il s'agit du même modèle de régression logistique vu au Cours n°06, avec
une fonction de lien logit, mais cette fois-ci sur plusieurs niveaux.

## Mise en pratique - absentéisme expérimental

```{r eval = TRUE, echo = TRUE}
prior6 <- c(
    prior(normal(0, 1), class = Intercept),
    prior(normal(0, 1), class = b),
    prior(cauchy(0, 1), class = sd),
    prior(lkj(2), class = cor)
    )
```

```{r eval = TRUE, echo = TRUE, results = "hide"}
mod6 <- brm(
    formula = presence | trials(total) ~ 1 + reminder + (1 + reminder | researcher), 
    family = binomial(link = "logit"),
    prior = prior6,
    data = absence_data,
    sample_prior = TRUE,
    warmup = 2000, iter = 10000,
    chains = 4, cores = 4,
    control = list(adapt_delta = 0.95),
    backend = "cmdstanr"
    )
```

## Mise en pratique - absentéisme expérimental

```{r eval = TRUE, echo = TRUE, fig.width = 12, fig.height = 6}
mod6 %>%
    plot(
        combo = c("dens_overlay", "trace"), pars = c("^b_", "^cor_"), widths = c(1, 1.5),
        theme = theme_bw(base_size = 16, base_family = "Open Sans")
        )
```

## Mise en pratique - absentéisme expérimental

Attention, les estimations ci-dessous sont dans l'espace log-odds...

```{r eval = TRUE, echo = TRUE}
posterior_summary(x = mod6, pars = c("^b_", "^sd_") )
```

. . .

Afin de pouvoir les interpréter il faut appliquer la transformation
logit-inverse. Par exemple, la probabilité de présence en moyenne (i.e.,
quel que soit le chercheur et pour toutes conditions confondues) est
égale à $p = \exp(\alpha) / (1 + \exp(\alpha) )$.

```{r eval = TRUE, echo = TRUE}
a <- fixef(mod6)[1] # on récupère la valeur de l'intercept
exp(a) / (1 + exp(a) ) # on "convertit" l'intercept en probabilité (équivalent à plogis(a))
```

## Mise en pratique - absentéisme expérimental

On s'est ensuite interrogé sur l'effet du mail de rappel. Ici encore, on
ne peut pas interpréter la pente directement... mais on sait que
$\text{exp}(\beta)$ nous donne un [odds
ratio](https://en.wikipedia.org/wiki/Odds_ratio) (i.e., un rapport de
cotes).

```{r eval = TRUE, echo = TRUE}
fixef(mod6)[2, c(1, 3, 4)] %>% exp()
```

Envoyer un mail de rappel multiplie par environ 18 la cote (i.e., le rapport $\frac{\Pr(\text{présent})}{\Pr(\text{absent})}$).

## Représenter les prédictions du modèle

Une manière de représenter les prédictions du modèle est de plotter
directement quelques échantillons issus de la distribution a posteriori.
On appelle ce genre de plot un "spaghetti plot".

```{r, echo = FALSE, eval = TRUE, message = FALSE, warning = FALSE, fig.width = 12, fig.height = 7}
library(tidybayes)
library(modelr)

absence_data %>%
    group_by(researcher, total) %>%
    data_grid(reminder = seq_range(reminder, n = 1e2) ) %>%
    add_fitted_samples(mod6, newdata = ., n = 100, scale = "linear") %>%
    mutate(estimate = plogis(estimate) ) %>%
    group_by(reminder, .iteration) %>%
    summarise(estimate = mean(estimate) ) %>%
    ggplot(aes(x = reminder, y = estimate, group = .iteration) ) +
    geom_hline(yintercept = 0.5, lty = 2) +
    geom_line(aes(y = estimate, group = .iteration), size = 0.5, alpha = 0.1) +
    labs(x = "Mail de rappel", y = "Pr(présent)")
```

## Représenter les prédictions du modèle

```{r, echo = TRUE, eval = TRUE, message = FALSE, warning = FALSE, fig.width = 16, fig.height = 6}
absence_data %>%
    group_by(researcher, total) %>%
    data_grid(reminder = seq_range(reminder, n = 1e2) ) %>%
    # add_fitted_samples(mod6, newdata = ., n = 100, scale = "linear") %>%
    add_linpred_draws(object = mod6, newdata = ., ndraws = 200) %>%
    # head()
    mutate(estimate = plogis(.linpred) ) %>%
    ggplot(aes(x = reminder, y = estimate, group = .draw) ) +
    geom_hline(yintercept = 0.5, lty = 2) +
    geom_line(aes(y = estimate, group = .draw), size = 0.5, alpha = 0.1) +
    facet_wrap(~researcher, nrow = 2) +
    labs(x = "Mail de rappel", y = "Pr(présent)")
```

## Test d'hypothèse - 1

Plusieurs manières de tester des hypothèses avec `brms`. La fonction
`hypothesis()` calcule un **evidence ratio** (équivalent au Bayes
factor). Lorsque l'hypothèse testée est une hypothèse ponctuelle (on
teste une valeur précise du paramètre, e.g., $\theta = 0$), cet
**evidence ratio** est approximé via la méthode de **Savage-Dickey**.
Cette méthode consiste simplement à comparer la densité du point testé
accordée par le prior à la densité accordée par la distribution a
posteriori.

```{r, echo = TRUE}
(hyp1 <- hypothesis(x = mod6, hypothesis = "reminder = 0") ) # Savage-Dickey Bayes factor
1 / hyp1$hypothesis$Evid.Ratio # BF10 = 1 / BF01 (and BF01 = 1 / BF10)
```

## Test d'hypothèse - 1

```{r, echo = TRUE, fig.width = 10, fig.height = 7}
plot(hyp1, plot = FALSE, theme = theme_bw(base_size = 20, base_family = "Open Sans") )[[1]] +
  geom_vline(xintercept = 0, linetype = 2) +
  coord_cartesian(xlim = c(-5, 5) )
```

## Test d'hypothèse - 1

Voir la vignette détaillée du paquet `bayestestR` concernant les facteurs de Bayes : <https://easystats.github.io/bayestestR/articles/bayes_factors.html>.

```{r, echo = TRUE, fig.width = 10, fig.height = 7}
library(bayestestR)
bf <- bayesfactor_parameters(posterior = mod6, null = 0)
plot(bf)
```

## Comparer le prior et le posterior

```{r, echo = TRUE, fig.width = 14, fig.height = 6}
data.frame(prior = hyp1$prior_samples$H1, posterior = hyp1$samples$H1) %>%
    gather(type, value) %>%
    mutate(type = factor(type, levels = c("prior", "posterior") ) ) %>%
    ggplot(aes(x = value) ) +
    geom_histogram(bins = 50, alpha = 0.8, col = "white", fill = "steelblue") +
    geom_vline(xintercept = 0, lty = 2, size = 1) +
    facet_wrap(~type, scales = "free") +
    labs(x = expression(beta[reminder]), y = "Nombre d'échantillons")
```

## Test d'hypothèse - 2

Une deuxième solution consiste à étendre l'approche par comparaison de
modèles. Tester une hypothèse revient à comparer deux modèles : un
modèle avec l'effet d'intérêt et un modèle sans l'effet d'intérêt.

```{r eval = TRUE, echo = TRUE, results = "hide"}
prior7 <- c(
    prior(normal(0, 10), class = Intercept, coef = ""),
    # prior(normal(0, 5), class = b)
    # prior(cauchy(0, 10), class = sd),
    prior(exponential(1), class = sd),
    prior(lkj(2), class = cor)
    )

mod7 <- brm(
    presence | trials(total) ~ 1 + reminder + (1 + reminder | researcher), 
    family = binomial(link = "logit"),
    prior = prior7,
    # prior = prior(normal(0, 5), class = Intercept, coef = ""),
    data = absence_data,
    # this line is important for bridgesampling
    save_pars = save_pars(all = TRUE),
    warmup = 2000, iter = 1e4, cores = 4,
    control = list(adapt_delta = 0.95) )

mod8 <- brm(
    presence | trials(total) ~ 1 + (1 + reminder | researcher), 
    family = binomial(link = "logit"),
    # prior = c(prior(normal(0, 5), class = Intercept, coef = ""), prior(normal(0, 5), class = b) ),
    prior = prior7,
    data = absence_data,
    save_pars = save_pars(all = TRUE),
    warmup = 2000, iter = 1e4, cores = 4,
    control = list(adapt_delta = 0.95) )
```

## Test d'hypothèse - 2

On peut ensuite comparer la vraisemblance marginale de ces modèles,
c'est à dire calculer un Bayes factor. Le paquet `brms` propose la
méthode `bayes_factor()` qui repose sur une approximation de la
vraisemblance marginale via le paquet `bridgesampling` [@gronau2017].

```{r eval = FALSE, echo = TRUE}
# returns the median BF based on 10 repetitions of the algorithm
bayes_factor(mod7, mod8, repetitions = 10, cores = 10)
```

. . .

```{r eval = TRUE, echo = FALSE, results = "hide"}
bf <- bayes_factor(mod7, mod8, repetitions = 10, cores = 10)
```

```{r eval = TRUE, echo = FALSE}
bf
```

## Comparaison de modèles

On peut également s'intéresser aux capacités de prédiction de ces deux
modèles et les comparer en utilisant des critères d'information. La
fonction `waic()` calcule le **Widely Applicable Information Criterion**
(cf. Cours n°07).

```{r, echo = TRUE, eval = TRUE}
waic(mod7, mod8, compare = FALSE)
```

## Posterior predictive checking

Une autre manière d'examiner les capacités de prédiction d'un modèle est
le **posterior predictive checking** (PPC). L'idée est simple : il
s'agit de comparer les données observées à des données simulées à partir
de la distribution **a posteriori**. Une fois qu'on a une distribution a
posteriori sur $\theta$, on peut simuler des données à partir de la
**posterior predictive distribution** :

$$p(\widetilde{y} \given y) = \int p(\widetilde{y} \given \theta) p(\theta \given y) d \theta$$

Si le modèle est un bon modèle, il devrait pouvoir générer des données
qui ressemblent aux données qu'on a observées [e.g., @gabry2019].

## Posterior predictive checking

On représente ci-dessous la distribution de nos données.

```{r, echo = TRUE, fig.width = 12, fig.height = 6}
absence_data %>%
    ggplot(aes(x = presence / total) ) +
    geom_density(fill = "grey20")
```

## Posterior predictive checking

Cette procédure est implémentée dans `brms` via la méthode `pp_check()`
qui permet de réaliser de nombreux checks. Par exemple, ci-dessous on
compare les prédictions a posteriori (n = 100) aux données observées.

```{r, echo = TRUE, fig.width = 12, fig.height = 6}
pp_check(object = mod7, ndraws = 1e2)
```

## Posterior predictive checking

```{r, echo = TRUE, fig.width = 12, fig.height = 8}
pp_check(object = mod7, ndraws = 1e3, type = "stat_2d")
```

## Ajuster le comportement de Stan

En fittant des modèles un peu compliqués, il se peut que vous obteniez
des messages d'avertissement du genre
"`There were x divergent transitions after warmup`". Dans cette
situation, on peut ajuster le comportement de `Stan` directement dans un
appel de la fonction `brm()` en utilisant l'argument `control`.

```{r eval = FALSE, echo = TRUE}
mod9 <- brm(
    formula = presence | trials(total) ~ 1 + reminder + (1 + reminder | researcher), 
    family = binomial(link = "logit"),
    data = absence_data,
    warmup = 2000, iter = 1e4,
    cores = parallel::detectCores(), # using all available cores
    control = list(adapt_delta = 0.95) # adjusting the delta step size
    )
```

On peut par exemple augmenter le pas de l'algorithme, via `adapt_delta`
(par défaut fixé à 0.8), ce qui ralentira probablement l'échantillonnage
mais améliorera la validité des échantillons obtenus. Plus généralement,
soyez attentifs aux messages d'erreur et d'avertissement générés par
`brms`.

## Tutoriels

Une liste d'articles de blog sur `brms` :
<https://paul-buerkner.github.io/blog/brms-blogposts/>.

L'article d'introduction du paquet `brms` [@bürkner2017] et la version
"advanced" [@bürkner2018].

Un tutoriel sur les modèles de régression logistique ordinale
[@bürkner2019].

Notre article tutoriel d'introduction aux modèles multi-niveaux avec
`brms` [@nalborczyk2019].

Application des modèles généralisés additifs multi-niveaux aux séries temporelles (e.g., M/EEG, iEEG, pupillometry, mouse-tracking) [@nalborczyk_precise_2025], voir le package `neurogam` (interface à `brms`): <https://lnalborczyk.github.io/neurogam/>.

## Bayesian workflow [@gelman2020]

```{r echo = FALSE, out.width = "66%"}
knitr::include_graphics("figures/bayes_workflow_1.png")
```

## Bayesian workflow [@gelman2020]

```{r echo = FALSE, out.width = "50%"}
knitr::include_graphics("figures/bayes_workflow_2.png")
```

## Conclusions

La statistique bayésienne est une approche générale de l'estimation de
paramètres. Cette approche utilise la théorie des probabilités pour
quantifier l'incertitude vis à vis de la valeur des paramètres de
modèles statistiques.

. . .

Ces modèles sont composés de différents blocs (e.g., fonction de
vraisemblance, priors, modèle linéaire ou non-linéaire) qui sont
modifiables à souhait. Ce qu'on appelle classiquement "conditions
d'application" sont simplement les conséquences des choix de
modélisation réalisés par l'utilisateur. Autrement dit, c'est
l'utilisateur qui choisit (et ne subit pas) les conditions
d'application.

. . .

Nous avons vu que le modèle de régression linéaire est un modèle très
flexible qui permet de décrire, via la modification de la fonction de
vraisemblance et via l'introduction de fonctions de lien, des relations
complexes (e.g., non-linéaires) entre variable prédite et variables
prédictrices. Ces modèles peuvent gagner en précision par la prise en
compte de la variabilité et des structures présentes dans les données
(cf. modèles multi-niveaux).

## Conclusions

Le paquet `brms` est un véritable couteau suisse de l'analyse
statistique bayésienne en `R`. Il permet de fitter presque n'importe
quel type de modèle de régression. Cela comprend tous les modèles que
nous avons vu en cours, mais également bien d'autres. Entre autres, des
modèles multivariés (i.e., avec plusieurs variables à prédire), des modèles
"distributionnels" (e.g., pour prédire des différence de variance), des
[modèles additifs](https://fromthebottomoftheheap.net/2018/04/21/fitting-gams-with-brms/),
des [procesus Gaussiens](https://rdrr.io/cran/brms/man/gp.html)
(Gaussian processes), des modèles issus de la [théorie de détection du
signal](https://mvuorre.github.io/posts/2017-10-09-bayesian-estimation-of-signal-detection-theory-models/),
des [modèles de mélange (mixture models)](https://www.martinmodrak.cz/2021/04/01/using-brms-to-model-reaction-times-contaminated-with-errors/),
des [modèles de diffusion](http://singmann.org/wiener-model-analysis-with-brms-part-i/),
des modèles [non-linéaires](https://paul-buerkner.github.io/brms/articles/brms_nonlinear.html)...

N'hésitez pas à me contacter pour plus d'informations sur ces modèles ou
si vous avez des questions par rapport à vos propres données. Vous
pouvez aussi contacter le créateur du paquet `brms`, très actif en ligne
(voir [son site](https://paul-buerkner.github.io/about/)). Voir aussi le
[forum Stan](https://discourse.mc-stan.org).

## Travaux pratiques - sleepstudy

```{r eval = TRUE, echo = TRUE}
library(lme4)
data(sleepstudy)
head(sleepstudy, 20)
```

## Travaux pratiques - sleepstudy

```{r eval = TRUE, echo = TRUE, fig.width = 12, fig.height = 6}
sleepstudy %>%
    ggplot(aes(x = Days, y = Reaction) ) +
    geom_smooth(method = "lm", colour = "black") +
    geom_point() +
    facet_wrap(~Subject, nrow = 2) +
    scale_x_continuous(breaks = c(0, 2, 4, 6, 8) )
```

## Travaux pratiques - sleepstudy

::: nonincremental
À vous de construire les modèles mathématiques et les modèles `brms`
correspondant aux modèles suivants :

-   Modèle avec seulement l'effet fixe de `Days`.
-   Modèle avec l'effet fixe de `Days` + un effet aléatoire de `Subject`
    (varying intercept).
-   Modèle avec l'effet fixe de `Days` + un effet aléatoire de `Subject`.
    (varying intercept) + un effet aléatoire de `Days` (varying
    slope).

Comparez ensuite ces modèles en utilisant les outils discutés aux cours
précédents (e.g., WAIC) et concluez.
:::

## Proposition de solution

```{r eval = TRUE, echo = TRUE}
fmod0 <- lm(Reaction ~ Days, sleepstudy)
fmod1 <- lmer(Reaction ~ Days + (1 | Subject), sleepstudy)
fmod2 <- lmer(Reaction ~ Days + (1 + Days | Subject), sleepstudy)

anova(fmod1, fmod2)
```

## Proposition de solution

```{r eval = TRUE, echo = TRUE, results = "hide"}
mod10 <- brm(
  Reaction ~ 1 + Days,
  prior = c(
    prior(normal(200, 100), class = Intercept),
    prior(normal(0, 10), class = b),
    prior(cauchy(0, 10), class = sigma)
    ),
  data = sleepstudy,
  warmup = 1000, iter = 5000,
  cores = parallel::detectCores()
  )
```

```{r eval = TRUE, echo = TRUE}
posterior_summary(mod10)
```

## Proposition de solution

```{r eval = TRUE, echo = TRUE, results = "hide"}
mod11 <- brm(
  Reaction ~ 1 + Days + (1 | Subject),
  prior = c(
    prior(normal(200, 100), class = Intercept),
    prior(normal(0, 10), class = b),
    prior(cauchy(0, 10), class = sigma),
    prior(cauchy(0, 10), class = sd)
    ),
  data = sleepstudy,
  warmup = 1000, iter = 5000,
  cores = parallel::detectCores()
  )
```

```{r eval = TRUE, echo = TRUE}
posterior_summary(mod11, pars = c("^b", "sigma") )
```

## Proposition de solution

```{r eval = TRUE, echo = TRUE, results = "hide"}
mod12 <- brm(
  Reaction ~ 1 + Days + (1 + Days | Subject),
  prior = c(
    prior(normal(200, 100), class = Intercept),
    prior(normal(0, 10), class = b),
    prior(cauchy(0, 10), class = sigma),
    prior(cauchy(0, 10), class = sd)
    ),
  data = sleepstudy,
  warmup = 1000, iter = 5000,
  cores = parallel::detectCores()
  )
```

```{r eval = TRUE, echo = TRUE}
posterior_summary(mod12, pars = c("^b", "sigma") )
```

## Proposition de solution

```{r eval = TRUE, echo = TRUE}
# calcul du WAIC et ajout du WAIC à chaque modèle
mod10 <- add_criterion(mod6, "waic")
mod11 <- add_criterion(mod7, "waic")
mod12 <- add_criterion(mod8, "waic")

# comparaison des WAIC de chaque modèle
w <- loo_compare(mod10, mod11, mod12, criterion = "waic")
print(w, simplify = FALSE)

# calcul du poids relatif de chaque modèle
model_weights(mod10, mod11, mod12, weights = "waic")
```

## Travaux pratiques

Ce jeu de données recense des données concernant 2000 élèves dans 100
écoles différentes. L'outcome principal est la popularité de l'élève,
évaluée sur une échelle de 1 à 10, et estimée en utilisant une procédure
sociométrique (i.e., on a demandé aux élèves de se noter mutuellement).
Ces élèves étaient également notés par leurs professeurs (colonne
`teachpop`), sur une échelle de 1 à 7. On dispose comme prédicteurs du
genre de l'élève (boy = 0, girl = 1) et de l'expérience du professeur
(`texp`, en années).

```{r eval = TRUE, echo = TRUE}
d <- open_data(popular)
head(d, 10)
```

## Travaux pratiques

À vous d'explorer ce jeu de données, de fitter quelques modèles (avec
`brms`) pour essayer de comprendre quels sont les facteurs qui
expliquent (permettent de prédire) la popularité d'un élève...

```{r echo = FALSE, out.width = "500px"}
knitr::include_graphics("figures/cat.gif")
```

## Proposition de solution - exploration graphique

```{r eval = TRUE, echo = TRUE, fig.width = 10, fig.height = 6}
d %>%
    ggplot(aes(x = popular) ) +
    geom_histogram() +
    facet_wrap(~sex) +
    scale_x_continuous(breaks = 1:10, limits = c(1, 10) )
```

## Proposition de solution - exploration graphique

```{r eval = TRUE, echo = TRUE, fig.width = 10, fig.height = 6}
d %>%
    ggplot(aes(x = texp, y = popular) ) +
    geom_point(alpha = 0.2) +
    geom_smooth(method = "lm", colour = "black") +
    facet_wrap(~sex)
```

## Proposition de solution

```{r eval = TRUE, echo = TRUE, results = "hide"}
d <- d %>%
    mutate(
        # using a sum contrast for gender
        sex = ifelse(sex == "boy", -0.5, 0.5),
        # centering and standardising teacher experience
        texp = scale(texp) %>% as.numeric
        )

prior13 <- c(
    prior(normal(5, 2.5), class = Intercept),
    prior(cauchy(0, 10), class = sd),
    prior(cauchy(0, 10), class = sigma)
    )

mod13 <- brm(
    formula = popular ~ 1 + (1 | school),
    data = d,
    prior = prior13,
    save_all_pars = TRUE,
    warmup = 2000, iter = 1e4, cores = 4
    )
```

## Proposition de solution

```{r eval = TRUE, echo = TRUE, results = "hide"}
prior14 <- c(
    prior(normal(0, 1), class = Intercept),
    prior(normal(0, 1), class = b),
    prior(cauchy(0, 1), class = sd),
    prior(cauchy(0, 10), class = sigma)
    )

mod14 <- brm(
    formula = popular ~ 1 + texp + (1 | school),
    data = d,
    prior = prior14,
    save_all_pars = TRUE,
    warmup = 2000, iter = 1e4, cores = 4
    )
```

## Proposition de solution

```{r eval = TRUE, echo = TRUE, results = "hide"}
prior15 <- c(
    prior(normal(0, 1), class = Intercept),
    prior(normal(0, 1), class = b),
    prior(cauchy(0, 1), class = sd),
    prior(cauchy(0, 10), class = sigma),
    prior(lkj(2), class = cor)
    )

mod15 <- brm(
    formula = popular ~ 1 + sex + texp + (1 + sex | school),
    data = d,
    prior = prior15,
    save_all_pars = TRUE,
    warmup = 2000, iter = 1e4, cores = 4
    )
```

## Proposition de solution

```{r eval = TRUE, echo = TRUE, results = "hide"}
mod16 <- brm(
    formula = popular ~ 1 + sex + texp + sex:texp + (1 + sex | school),
    data = d,
    prior = prior13,
    save_all_pars = TRUE,
    warmup = 2000, iter = 1e4, cores = 4
    )
```

```{r eval = TRUE, echo = TRUE}
# calcul du WAIC et ajout du WAIC à chaque modèle
mod13 <- add_criterion(mod13, "waic")
mod14 <- add_criterion(mod14, "waic")
mod15 <- add_criterion(mod15, "waic")
mod16 <- add_criterion(mod16, "waic")
```

## Proposition de solution

```{r eval = TRUE, echo = TRUE}
# comparaison des WAIC de chaque modèle
model_comparison_table <- loo_compare(mod13, mod14, mod15, mod16, criterion = "waic") %>%
  data.frame() %>%
  rownames_to_column(var = "model")

weights <- data.frame(weight = model_weights(mod13, mod14, mod15, mod16, weights = "waic") ) %>%
  round(digits = 3) %>%
  rownames_to_column(var = "model")

left_join(model_comparison_table, weights, by = "model")
```

## Proposition de solution

Les prédictions du modèle ne coïncident pas exactement avec les données
car ces dernières sont discrètes Les élèves étaient notés sur une
échelle discrète allant de 1 à 10 (un élève ne pouvait pas avoir
une note de 3.456). Ce type de données peut-être approximée par une
distribution normale (comme nous l'avons fait) mais ce choix n'est pas
optimal en termes de prédiction...

```{r eval = TRUE, echo = TRUE, fig.width = 10, fig.height = 5}
pp_check(object = mod16, ndraws = 1e2)
```

## Proposition de solution

On pourrait choisir un modèle qui se rapproche du processus de
génération des données. C'est le cas du modèle de régression logistique
ordinale (ordered categorical model). Ce modèle est une sorte de
généralisation à plus de 2 catégories du modèle de régression logistique
vu au Cours n°06 (voir ce
[blogpost](https://kevinstadler.github.io/blog/bayesian-ordinal-regression-with-random-effects-using-brms/)
pour plus de détails, ou le chapitre 11 de Statistical Rethinking), sauf
que les catégories sont ordonnées.

$$
\begin{aligned}
\color{orangered}{\text{pop}_{i}} \ &\color{orangered}{\sim \mathrm{Categorical}(\mathbf{p})} \\
\color{black}{\text{logit}(p_{k})} \ &\color{black}{= \alpha_{k}} \\
\color{steelblue}{\alpha_{k}} \ &\color{steelblue}{\sim \mathrm{Normal}(0, 10)} \\
\end{aligned}
$$

Où la distribution $\mathrm{Categorical}$ est une distribution discrète
qui prend un vecteur de probabilités
$\mathbf{p} = \{p_{1}, p_{2}, p_{3}, p_{4}, p_{5}, p_{6}, p_{7}, p_{8}, p_{9}\}$
qui correspondent aux probabilités cumulées de chaque réponse (entre 1
et 10, 10 ayant une probabilité cumulée de 1).

## Proposition de solution

On définit une série de $N - 1$ intercepts
$\mathbf{p} = \{p_{1}, p_{2}, p_{3}, p_{4}, p_{5}, p_{6}, p_{7}, p_{8}, p_{9}\}$
sur le logarithme de la cote cumulée (log-cumulative-odds).

$$\text{logit}(p_{k}) = \log \frac{\Pr(y_{i} \leq k)}{1 - \Pr(y_{i} \leq k)} = \alpha_{k}$$

```{r eval = TRUE, echo = FALSE, fig.width = 14, fig.height = 6}
library(patchwork)

p1 <-
  d %>% 
  ggplot(aes(x = popular, fill = ..x..) ) +
  geom_histogram(binwidth = 0.5, size = 0) +
  scale_x_continuous(breaks = 1:10, limits = c(1, 10) ) +
  labs(x = "Popularité", y = "Nombre de réponses") +
  theme_bw(base_size = 16, base_family = "Open Sans") +
  theme(
    axis.title.y = element_text(angle = 90),
    legend.position = "none"
    )

p2 <-
  d %>%
  count(popular) %>%
  mutate(pr_k = n / nrow(d), cum_pr_k = cumsum(pr_k) ) %>% 
  ggplot(aes(x = popular, y = cum_pr_k, color = popular, fill = popular) ) +
  geom_line() +
  geom_point(shape = 21, color = "white", size = 2.5, stroke = 1) +
  labs(x = "Popularité", y = "Proportion cumulée") +
  theme_bw(base_size = 16, base_family = "Open Sans") +
  scale_x_continuous(breaks = 1:10, limits = c(1, 10) ) +
  theme(
    axis.title.y = element_text(angle = 90),
    legend.position = "none"
    )

p3 <-
  d %>%
  count(popular) %>%
  mutate(cum_pr_k = cumsum(n / nrow(d) ) ) %>% 
  filter(popular < 9) %>% 
  ggplot(aes(
    x = popular, y = log(cum_pr_k / (1 - cum_pr_k) ),
    color = popular, fill = popular
    ) ) +
  geom_line() +
  geom_point(shape = 21, colour = "white", size = 2.5, stroke = 1) +
  labs(x = "Popularité", y = "Log cote cumulée") +
  theme_bw(base_size = 16, base_family = "Open Sans") +
  scale_x_continuous(breaks = 1:10, limits = c(1, 10) ) +
  theme(
    axis.title.y = element_text(angle = 90),
    legend.position = "none"
    )

(p1 | p2 | p3)
```

## Proposition de solution

La vraisemblance de l'observation $k$ (e.g., `pop = 3`) est donnée par
soustraction des proportions cumulées. Cette vraisemblance est
représentée par les barres verticales sur le graphique ci-dessous.

$$p_{k} = \Pr(y_{i} = k) = \Pr(y_{i} \leq k) - \Pr(y_{i} \leq k -1)$$

```{r eval = TRUE, echo = FALSE, fig.width = 6, fig.height = 6}
d_plot <- d %>%
  count(popular) %>%
  mutate(pr_k = n / nrow(d), cum_pr_k = cumsum(n / nrow(d) ) ) %>%
  mutate(discrete_probability = ifelse(popular == 1, cum_pr_k, cum_pr_k - pr_k) )

text <- tibble(
  text = 2:9,
  popular = seq(from = 2.25, to = 9.25, by = 1),
  cum_pr_k = d_plot$cum_pr_k - 0.065
  )

d_plot %>% 
  ggplot(aes(x = popular, y = cum_pr_k, color = cum_pr_k, fill = cum_pr_k) ) +
  geom_line() +
  geom_point(shape = 21, colour = "white", size = 2.5, stroke = 1) +
  geom_linerange(aes(ymin = 0, ymax = cum_pr_k), alpha = 0.5) +
  geom_linerange(
    aes(
      x = popular + .025,
      ymin = ifelse(popular == 1, 0, discrete_probability),
      ymax = cum_pr_k),
    color = "black"
    ) +
  geom_text(data = text,aes(label = text), size = 4) +
  scale_x_continuous(breaks = 2:9) +
  labs(x = "Popularité", y = "Proportion cumulée") +
  theme_bw(base_size = 16, base_family = "Open Sans") +
  theme(
    axis.title.y = element_text(angle = 90),
    legend.position = "none"
    )
```

## Proposition de solution

NB : Ce modèle peut prendre plusieurs heures selon votre système...

```{r eval = TRUE, echo = TRUE, results = "hide"}
mod17 <- brm(
    popular ~ 1 + sex + texp + sex:texp + (1 | school),
    data = d,
    prior = prior14,
    warmup = 1000, iter = 5000,
    chains = 4, cores = 4,
    threads = threading(threads = 2),
    file = "models/mod17", backend = "cmdstanr"
    )
```

```{r eval = TRUE, echo = TRUE, results = "hide"}
prior18 <- c(
    brms::prior(normal(0, 10), class = Intercept),
    brms::prior(normal(0, 10), class = b),
    brms::prior(cauchy(0, 10), class = sd)
    )

mod18 <- brm(
    popular ~ 1 + sex + texp + sex:texp + (1 | school),
    data = d,
    family = cumulative(link = "logit"),
    prior = prior18,
    chains = 4, cores = 4,
    control = list(adapt_delta = 0.99, max_treedepth = 15),
    threads = threading(threads = 2),
    file = "models/mod18", backend = "cmdstanr"
    )
```

## Proposition de solution

```{r eval = TRUE, echo = TRUE}
waic(mod17, mod18, compare = FALSE)
```

## Proposition de solution

```{r eval = TRUE, echo = TRUE, fig.width = 12, fig.height = 6}
pp_check(mod18, ndraws = 1e2, type = "bars", prob = 0.95, freq = FALSE) +
  scale_x_continuous(breaks = 1:9) +
  labs(x = "Popularité", y = "Proportion")
```

## Références {.refs}
